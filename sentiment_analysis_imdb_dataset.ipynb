{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "204865a1",
      "metadata": {
        "id": "204865a1"
      },
      "source": [
        "## Sentiment Analysis on IMDB DATASET\n",
        "Steps\n",
        "1. Load the dataset\n",
        "2. Clean Dataset\n",
        "3. Encode sentiments\n",
        "4. Split dataset\n",
        "5. Tokenize and Pad/Trancate Reviews\n",
        "6. Build the architecture/Model\n",
        "7. Train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## install anvil\n",
        "## anvil is a platform that allows users to build web apps using python\n",
        "!pip install anvil-uplink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "b50l0fk2zv4s",
        "outputId": "7b608fc0-b4dc-4a1c-a060-53bec9740e12"
      },
      "id": "b50l0fk2zv4s",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n",
            "Collecting ws4py (from anvil-uplink)\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45228 sha256=bb9baeb58ab832b628a83a0f2810eba8770dc2153352253f653a8206a8998e33\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/7c/ad/d9c746276bf024d44296340869fcb169f1e5d80fb147351a57\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anvil.server"
      ],
      "metadata": {
        "id": "EPAvAUZa02hw"
      },
      "id": "EPAvAUZa02hw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.connect('server_SKD63ST5DDDR7VEHAZMV3ICS-T3JFQWAZ6FKEY6WB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1OTVJ5z07-q",
        "outputId": "0ccc0224-859b-406f-8dce-65cdcecfc42b"
      },
      "id": "h1OTVJ5z07-q",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9e374e06",
      "metadata": {
        "id": "9e374e06"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "06b915fe",
      "metadata": {
        "id": "06b915fe"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbVg4ShYrffs",
        "outputId": "d0bd630b-4d9d-4d15-803c-3f16ca20f570"
      },
      "id": "XbVg4ShYrffs",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "11e7bfa4",
      "metadata": {
        "id": "11e7bfa4"
      },
      "outputs": [],
      "source": [
        "english_stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a63fa99d",
      "metadata": {
        "id": "a63fa99d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d4155d-3bda-412c-ae0d-5e643ad5a435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews\n",
            "0        [One, reviewers, mentioned, watching, Oz, epis...\n",
            "1        [A, wonderful, little, production, The, filmin...\n",
            "2        [I, thought, wonderful, way, spend, time, hot,...\n",
            "3        [Basically, family, little, boy, Jake, thinks,...\n",
            "4        [Petter, Mattei, Love, Time, Money, visually, ...\n",
            "                               ...                        \n",
            "49995    [I, thought, movie, right, good, job, It, crea...\n",
            "49996    [Bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [I, Catholic, taught, parochial, elementary, s...\n",
            "49998    [I, going, disagree, previous, comment, side, ...\n",
            "49999    [No, one, expects, Star, Trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def load_dataset():\n",
        "    df = pd.read_csv('IMDB Dataset.csv')\n",
        "    x_data = df['review']\n",
        "    y_data = df['sentiment']\n",
        "\n",
        "    # pre-process review\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex=True) # remove HTML tags\n",
        "    x_data = x_data.replace({'[^A-za-z]': ' '}, regex=True) # removes non alphabets\n",
        "    x_data = x_data.apply(lambda review : [w for w in review.split() if w not in english_stops]) # remove stop words\n",
        "    #x_data = x_data.apply(lambda review : [w.lower() for w in review])\n",
        "\n",
        "    # encode sentiment\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data, '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "327a559f",
      "metadata": {
        "id": "327a559f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4969a3e0-c751-4e3b-94d1-57411b93ba54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set\n",
            "28729    [Valley, Girl, always, hold, special, place, h...\n",
            "29579    [This, Paul, F, Ryan, first, full, length, fea...\n",
            "30349    [An, unusual, film, Ringo, Lam, one, strangely...\n",
            "43283    [One, sensible, comedies, hit, Hindi, film, sc...\n",
            "28823    [I, watched, film, based, favorable, reviews, ...\n",
            "                               ...                        \n",
            "22934    [Although, first, Hunter, S, Thompson, documen...\n",
            "35935    [I, huge, fan, Emily, Watson, Breaking, The, W...\n",
            "21694    [This, terrible, film, Angie, Dickenson, class...\n",
            "45566    [One, beautiful, movies, ever, made, ex, Yu, S...\n",
            "45857    [While, movie, titles, contains, word, Mother,...\n",
            "Name: review, Length: 40000, dtype: object \n",
            "\n",
            "48223    [The, plot, something, white, hunters, capture...\n",
            "5121     [I, guy, hesitant, watch, movie, know, Richard...\n",
            "43392    [The, original, title, means, The, Birth, Octo...\n",
            "6097     [I, say, Seventeen, Missing, much, better, I, ...\n",
            "36643    [I, deeply, moved, movie, many, respects, Firs...\n",
            "                               ...                        \n",
            "11908    [Fred, Gwynne, Al, Lewis, Sid, Caesar, Yvonne,...\n",
            "47814    [I, high, hopes, film, I, saw, listing, decide...\n",
            "1292     [Alien, excellent, Many, writers, tried, copy,...\n",
            "20243    [When, movie, released, biggest, hit, soon, be...\n",
            "37103    [The, movie, opens, beautiful, landscape, shot...\n",
            "Name: review, Length: 10000, dtype: object \n",
            "\n",
            "Test Set\n",
            "28729    1\n",
            "29579    1\n",
            "30349    1\n",
            "43283    1\n",
            "28823    0\n",
            "        ..\n",
            "22934    0\n",
            "35935    0\n",
            "21694    0\n",
            "45566    1\n",
            "45857    1\n",
            "Name: sentiment, Length: 40000, dtype: int64 \n",
            "\n",
            "48223    0\n",
            "5121     1\n",
            "43392    1\n",
            "6097     1\n",
            "36643    1\n",
            "        ..\n",
            "11908    1\n",
            "47814    0\n",
            "1292     0\n",
            "20243    0\n",
            "37103    0\n",
            "Name: sentiment, Length: 10000, dtype: int64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Split datasets\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
        "\n",
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a800e3a5",
      "metadata": {
        "id": "a800e3a5"
      },
      "outputs": [],
      "source": [
        "# getting maximum review length\n",
        "\n",
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ded68e08",
      "metadata": {
        "id": "ded68e08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c86480-c889-44bd-bb63-3cae90cf1eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[3499  152  122 ...  157   33    5]\n",
            " [   8  701 1042 ...  156  591 4935]\n",
            " [ 697 1713    4 ...    0    0    0]\n",
            " ...\n",
            " [   8  287    4 ...    0    0    0]\n",
            " [   5  214   28 ...    0    0    0]\n",
            " [ 376    3 2777 ... 4504 6374  207]] \n",
            "\n",
            "Encoded X Test\n",
            " [[    2    42    61 ...     0     0     0]\n",
            " [    1   119 11816 ...     0     0     0]\n",
            " [    2   123   324 ...   744     3   244]\n",
            " ...\n",
            " [ 1063   224    37 ...     0     0     0]\n",
            " [  170     3   514 ...   450   446   627]\n",
            " [    2     3  2032 ...     5 18127  1546]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ],
      "source": [
        "# Tokenize and pad/truncate reviews\n",
        "# a neural network using accepts numerical data, so we need to encode the reviews\n",
        "# use tensorflow tokenizer to encode reviews to integers where each\n",
        "# word unique word is automically indexed based on x_train\n",
        "\n",
        "# use pad_sequence to truncate all reviews to the same length\n",
        "\n",
        "token = Tokenizer() # data already lowered\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "598b2cff",
      "metadata": {
        "id": "598b2cff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c56228-cfb6-4663-dd1d-1beab2f82746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 130, 32)           2984480   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                24832     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3009377 (11.48 MB)\n",
            "Trainable params: 3009377 (11.48 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a1fa0223",
      "metadata": {
        "id": "a1fa0223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d5854b-1c69-4d32-c900-9f39f47c4fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.5275\n",
            "Epoch 1: accuracy improved from -inf to 0.52747, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 50s 140ms/step - loss: 0.6887 - accuracy: 0.5275\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.7288\n",
            "Epoch 2: accuracy improved from 0.52747 to 0.72880, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 29s 92ms/step - loss: 0.5778 - accuracy: 0.7288\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.5102 - accuracy: 0.7994\n",
            "Epoch 3: accuracy improved from 0.72880 to 0.79935, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.5102 - accuracy: 0.7994\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.7987\n",
            "Epoch 4: accuracy did not improve from 0.79935\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4882 - accuracy: 0.7987\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.8256\n",
            "Epoch 5: accuracy improved from 0.79935 to 0.82563, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.4467 - accuracy: 0.8256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6e1e8df820>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "281318ce",
      "metadata": {
        "id": "281318ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7267b6c8-e835-4919-8915-74074c309592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Prediction: 0\n",
            "Wrong Prediction: 10000\n",
            "Accuracy: 0.0\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.4535 - accuracy: 0.8277\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict_on_batch(x_test)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "25466e81",
      "metadata": {
        "id": "25466e81"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model('models/LSTM.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3f5aab0d",
      "metadata": {
        "id": "3f5aab0d"
      },
      "outputs": [],
      "source": [
        "## plot the training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0a81aa66",
      "metadata": {
        "id": "0a81aa66"
      },
      "outputs": [],
      "source": [
        "# Pre-process input\n",
        "# adding everything in a single function makes\n",
        "# it easily callable on the anvil server\n",
        "# classify_review function takes a review (from the web page),\n",
        "# runs inference on the review and returns a probabilistic value\n",
        "# to determine whether the review was positive or negative.\n",
        "@anvil.server.callable\n",
        "def classify_review(review):\n",
        "  regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "  review = regex.sub('', review)\n",
        "  print('Cleaned: ', review)\n",
        "\n",
        "  words = review.split(' ')\n",
        "  filtered = [w for w in words if w not in english_stops]\n",
        "  filtered = ' '.join(filtered)\n",
        "  filtered = [filtered.lower()]\n",
        "  print('Filtered: ', filtered)\n",
        "\n",
        "  tokenize_words = token.texts_to_sequences(filtered)\n",
        "  tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "  result = loaded_model.predict(tokenize_words)\n",
        "  print(result)\n",
        "\n",
        "  if result <= 0.7:\n",
        "    return 'negative'\n",
        "  else:\n",
        "    return 'positive'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## print the keywords from the review\n",
        "import anvil.mpl_util\n",
        "\n",
        "@anvil.server.callable\n",
        "def print_key_words(review):\n",
        "  ## plot key words as a word cloud followed by the classification\n",
        "  wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(review)\n",
        "  plt.figure()\n",
        "  plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "  plt.axis(\"off\")\n",
        "  ## plt.show()\n",
        "  return anvil.mpl_util.plot_image()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ji8KreiC8zQx"
      },
      "id": "ji8KreiC8zQx",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b46a7d",
      "metadata": {
        "id": "01b46a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f658fa-b193-470c-bb8f-3ca233d4ec7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned:  This is a very good movie and I recommend \n",
            "Filtered:  ['this good movie i recommend ']\n",
            "1/1 [==============================] - 0s 329ms/step\n",
            "[[0.88820887]]\n"
          ]
        }
      ],
      "source": [
        "anvil.server.wait_forever()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vr2_QbBk6H5E"
      },
      "id": "vr2_QbBk6H5E",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}